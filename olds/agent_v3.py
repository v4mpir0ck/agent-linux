# Versi√≥n 3 - Agente IA Linux (Azure OpenAI)
# Backup completo antes de nuevos cambios

# Esta versi√≥n incluye:
# - Procesamiento de cualquier instrucci√≥n por LLM real (Azure OpenAI)
# - Prompt seguro y expl√≠cito para troubleshooting
# - Sin l√≥gica hardcodeada para instrucciones
# - Manejo profesional de outputs y confirmaciones

# Copia √≠ntegra del agente.py actual

def print_help():
    import shutil
    def center_text(text, width):
        return text.center(width)
    def wrap_text(text, width):
        import textwrap
        return textwrap.wrap(text, width)
    box_width = min(90, shutil.get_terminal_size((80, 20)).columns - 2)
    opciones_basicas = [
        "  errores: Buscar errores recientes y sugerir soluciones",
        "üìù  logs: Ver y filtrar logs del sistema y servicios",
        "üñ•Ô∏è  sistema: Info del sistema operativo",
        "üßÆ  cpu: Info de la CPU",
        "üíæ  memoria: Info de la memoria RAM",
        "üìÄ  disco: Info de discos y particiones",
        "üåê  red: Info de interfaces de red",
        "üì°  conectividad: Chequeo de conexi√≥n a Internet",
        "üõ°Ô∏è  firewall: Estado del firewall",
        "üìä  procesos: Procesos m√°s consumidores",
        "üë•  usuarios: Usuarios conectados",
        "üîß  servicio <nombre>: Estado de un servicio (ej: servicio sshd)",
        "üóÇÔ∏è  dns: Muestra servidores DNS del sistema",
    ]
    opciones_avanzadas = [
        "üß≠  wizard: Modo interactivo guiado para troubleshooting",
        "ü§ñ  auto-reparaci√≥n: Ejecutar comandos seguros para resolver problemas comunes",
        "üìÑ  informe: Generar resumen de estado del sistema",
        "üö®  alertas: Sugerir acciones ante problemas detectados",
        "‚öôÔ∏è  configuraci√≥n: Mostrar y comparar archivos clave",
        "üõ†Ô∏è  herramientas: Ejecutar nmap, netstat, lsof, ss, tcpdump",
        "üîó  conectividad externa: Test de acceso a endpoints y APIs",
        "üåê  ping: Diagn√≥stico de red (ping, traceroute, test de velocidad)",
    ]
    banner = "\033[96m+{}+\033[0m\n".format('-'*box_width)
    banner += "\033[96m|{}|\033[0m\n".format(center_text('üß†  Agente IA para Linux  üß†', box_width))
    banner += "\033[96m+{}+\033[0m\n".format('-'*box_width)
    banner += "| \033[96mOpciones b√°sicas:\033[0m".ljust(box_width) + "|\n"
    for opcion in opciones_basicas:
        opcion = opcion.strip().replace('\n', ' ')
        if len(opcion) > box_width-2:
            opcion = opcion[:box_width-5] + '...'
        banner += f"| \033[96m{opcion.ljust(box_width-2)}\033[0m |\n"
    banner += "|" + ("-" * (box_width)) + "|\n"
    banner += "| \033[96mOpciones avanzadas:\033[0m".ljust(box_width) + "|\n"
    for opcion in opciones_avanzadas:
        opcion = opcion.strip().replace('\n', ' ')
        if len(opcion) > box_width-2:
            opcion = opcion[:box_width-5] + '...'
        banner += f"| \033[96m{opcion.ljust(box_width-2)}\033[0m |\n"
    banner += "\033[96m+{}+\033[0m\n".format('-'*box_width)
    return banner
    return banner


# --- CLASE AGENT AL NIVEL SUPERIOR ---
class Agent:
    def llm_procesar_respuesta(self, instruccion, respuesta=None):
        """
        El LLM sugiere el comando a ejecutar para la instrucci√≥n dada. Si la respuesta ya viene dada, la muestra; si no, decide el comando y lo ejecuta.
        Si el comando es peligroso, pide confirmaci√≥n antes de ejecutar.
        """
        import subprocess
        peligrosas = [
            "rm ", "borrar", "eliminar", "modificar", "restart", "systemctl restart", "shutdown", "reboot", "apt-get", "chmod", "chown", "kill", "useradd", "userdel", "mkfs", "dd ", "mount", "umount", "echo >", "> /", ">> /", "truncate", "passwd", "service "]
        if respuesta is not None:
            lower_resp = str(respuesta).lower()
            if any(p in lower_resp for p in peligrosas):
                print("\033[93m[IA] La acci√≥n sugerida puede modificar el sistema o ser peligrosa.\033[0m")
                print(f"\033[93m[IA] Respuesta sugerida por LLM:\033[0m {respuesta}")
                confirm = input("¬øDeseas continuar con esta acci√≥n? (s√≠/no): ")
                if confirm.strip().lower() in ["si", "s√≠", "s", "yes", "y"]:
                    return f"[LLM IA] Acci√≥n confirmada y ejecutada/sugerida:\n{respuesta}"
                else:
                    return "[LLM IA] Acci√≥n cancelada por el usuario."
            else:
                return f"[LLM IA] Respuesta sugerida:\n{respuesta}"
        comando_llm = self.llm_sugerir_comando(instruccion)
        TABLE_WIDTH = 90
        marco = '-' * TABLE_WIDTH
        def box_line(text, color='96'):
            return f"\033[{color}m| {text[:TABLE_WIDTH-4].ljust(TABLE_WIDTH-4)} |\033[0m"
        if any(p in comando_llm.lower() for p in peligrosas):
            print("\033[93m[IA] El comando sugerido puede modificar el sistema o ser peligroso.\033[0m")
            cmd_box = f"\033[96m{marco}\033[0m\n" \
                      f"\033[96m|{'COMANDO SUGERIDO POR LLM':^{TABLE_WIDTH-2}}|\033[0m\n" \
                      f"\033[96m{marco}\033[0m\n" \
                      f"\033[96m| {comando_llm.ljust(TABLE_WIDTH-4)} |\033[0m\n" \
                      f"\033[96m{marco}\033[0m\n"
            print(cmd_box)
            confirm = input("¬øDeseas ejecutar este comando? (s√≠/no): ")
            if confirm.strip().lower() not in ["si", "s√≠", "s", "yes", "y"]:
                return "[LLM IA] Acci√≥n cancelada por el usuario."
        try:
            output = subprocess.check_output(comando_llm, shell=True, stderr=subprocess.STDOUT, universal_newlines=True, timeout=10)
        except Exception as e:
            output = f"[Error] {e}"
        cmd_box = f"\033[96m{marco}\033[0m\n" \
                  f"\033[96m|{'COMANDO SUGERIDO POR LLM':^{TABLE_WIDTH-2}}|\033[0m\n" \
                  f"\033[96m{marco}\033[0m\n" \
                  f"\033[96m| {comando_llm.ljust(TABLE_WIDTH-4)} |\033[0m\n" \
                  f"\033[96m{marco}\033[0m\n"
        output_box = f"\n\033[92m{marco}\033[0m\n" \
                     f"\033[92m|{'OUTPUT':^{TABLE_WIDTH-2}}|\033[0m\n" \
                     f"\033[92m{marco}\033[0m\n"
        for linea in output.splitlines() or [output]:
            output_box += f"\033[92m| {linea[:TABLE_WIDTH-4].ljust(TABLE_WIDTH-4)} |\033[0m\n"
        output_box += f"\033[92m{marco}\033[0m"
        return f"{cmd_box}{output_box}"
        """
        Simula el procesamiento de la respuesta por el LLM. Si detecta que la respuesta implica acci√≥n peligrosa o modificaci√≥n,
        pide confirmaci√≥n antes de mostrarla/ejecutarla. Si es solo informativa, la muestra directamente.
        """
        peligrosas = [
            "rm ", "borrar", "eliminar", "modificar", "restart", "systemctl restart", "shutdown", "reboot", "apt-get", "chmod", "chown", "kill", "useradd", "userdel", "mkfs", "dd ", "mount", "umount", "echo >", "> /", ">> /", "truncate", "passwd", "service "]
        lower_resp = str(respuesta).lower()
        if any(p in lower_resp for p in peligrosas):
            print("\033[93m[IA] La acci√≥n sugerida puede modificar el sistema o ser peligrosa.\033[0m")
            print(f"\033[93m[IA] Respuesta sugerida por LLM:\033[0m {respuesta}")
            confirm = input("¬øDeseas continuar con esta acci√≥n? (s√≠/no): ")
            if confirm.strip().lower() in ["si", "s√≠", "s", "yes", "y"]:
                return f"[LLM IA] Acci√≥n confirmada y ejecutada/sugerida:\n{respuesta}"
            else:
                return "[LLM IA] Acci√≥n cancelada por el usuario."
        else:
            return f"[LLM IA] Respuesta sugerida:\n{respuesta}"
    def handle_instruction(self, instruccion):
        """
        Maneja la instrucci√≥n del usuario. Si la instrucci√≥n es 'ayuda', 'opciones', 'menu', etc., muestra el banner de ayuda.
        Si es la instrucci√≥n de arranque (vac√≠a), muestra el mismo banner que print_help.
        Si es una instrucci√≥n reconocida, responde con un mensaje simulado.
        """
        ayuda_triggers = ["ayuda", "opciones", "menu", "qu√© puedes hacer", "help"]
        if instruccion.strip() == "":
            import sys
            if __name__ == "__main__" or sys.argv[0].endswith("__main__.py"):
                from agente.agent import print_help
            else:
                from ..agent import print_help
            return print_help()
        if any(trigger in instruccion.lower() for trigger in ayuda_triggers):
            from ..agent import print_help
            return print_help()
        if "auto-reparaci√≥n" in instruccion.lower() or "autoreparaci√≥n" in instruccion.lower():
            import subprocess
            pasos = [
                "Detectar servicios ca√≠dos",
                "Reiniciar servicios cr√≠ticos si est√°n ca√≠dos",
                "Limpiar espacio en disco si est√° lleno",
                "Reparar configuraciones de red si hay fallos de conectividad"
            ]
            acciones_ejecutadas = []
            print("\n\033[96m+{}+\033[0m".format('-'*60))
            print("\033[96m|{:^58}|\033[0m".format('AUTO-REPARACI√ìN IA: Propuesta de acciones'))
            print("\033[96m+{}+\033[0m".format('-'*60))
            for paso in pasos:
                comando_llm = self.llm_sugerir_comando(paso)
                print("\033[96m|{:^58}|\033[0m".format(f"Acci√≥n: {paso}"))
                print("\033[96m|{:^58}|\033[0m".format(f"Comando IA: {comando_llm}"))
                print("\033[96m+{}+\033[0m".format('-'*60))
                confirm = input(f"¬øDeseas ejecutar este comando? (s√≠/no): ")
                if confirm.strip().lower() in ["si", "s√≠", "s", "yes", "y"]:
                    try:
                        if any(p in comando_llm for p in ["restart", "rm -rf", "apt-get clean"]):
                            output = f"[Simulaci√≥n] Comando '{comando_llm}' ejecutado (no real por seguridad)."
                        else:
                            output = subprocess.check_output(comando_llm, shell=True, stderr=subprocess.STDOUT, universal_newlines=True, timeout=10)
                    except Exception as e:
                        output = f"[Error o Simulaci√≥n] {e}"
                    print("\033[92m+{}+\033[0m".format('-'*60))
                    print("\033[92m|{:^58}|\033[0m".format('RESULTADO DE LA ACCI√ìN'))
                    print("\033[92m+{}+\033[0m".format('-'*60))
                    for linea in output.splitlines() or [output]:
                        print(f"\033[92m| {linea[:56].ljust(56)} |\033[0m")
                    print("\033[92m+{}+\033[0m\n".format('-'*60))
                    acciones_ejecutadas.append(f"{paso} (cmd: {comando_llm})")
            if acciones_ejecutadas:
                resumen = '\n'.join(f"‚úîÔ∏è {a}" for a in acciones_ejecutadas)
                return f"[Auto-reparaci√≥n] Acciones ejecutadas:\n{resumen}\nReparaci√≥n completada."
            else:
                return "[Auto-reparaci√≥n] No se ha realizado ninguna acci√≥n."
        instr = instruccion.lower().strip()
        tokens = instr.split()
        if instr in ["red", "network"]:
            return self.llm_procesar_respuesta(instruccion)
        if instr in ["disco", "disk"]:
            return self.llm_procesar_respuesta(instruccion)
        if instr in ["memoria", "ram", "que memoria tengo", "mem"]:
            return self.llm_procesar_respuesta(instruccion)
        if instr in ["cpu", "procesador"]:
            return self.llm_procesar_respuesta(instruccion)
        if instr in ["conectividad", "internet"]:
            return self.llm_procesar_respuesta(instruccion)
        if instr in ["firewall"]:
            return self.llm_procesar_respuesta(instruccion)
        if instr in ["usuarios", "users"]:
            return self.llm_procesar_respuesta(instruccion)
        if instr in ["procesos", "top", "top procesos"]:
            return self.llm_procesar_respuesta(instruccion)
        if instr.startswith("servicio"):
            return self.llm_procesar_respuesta(instruccion)
        if instr in ["dns"]:
            return self.llm_procesar_respuesta(instruccion)
        if instr in ["logs", "log"]:
            return self.llm_procesar_respuesta(instruccion)
        if instr in ["errores", "error"]:
            return self.llm_procesar_respuesta(instruccion)
        if instr in ["sistema", "so", "s.o."]:
            return self.llm_procesar_respuesta(instruccion)
        return self.llm_procesar_respuesta(instruccion)

    def llm_sugerir_comando(self, instruccion):
        """
        Usa Azure OpenAI (API) para sugerir el comando shell a ejecutar seg√∫n la instrucci√≥n del usuario.
        Devuelve solo el comando shell sugerido (sin explicaci√≥n).
        """
        import requests
        AZURE_OPENAI_KEY = "8zKFs1zJ1el0qP7er2oHsKusPGieAZERSUiTHACifNQ844TfNX1oJQQJ99BHACYeBjFXJ3w3AAABACOGJckA"
        AZURE_OPENAI_ENDPOINT = "https://agent-linux.openai.azure.com/"
        AZURE_OPENAI_DEPLOYMENT = "gpt-4.1-mini"
        API_VERSION = "2024-02-15-preview"
        url = f"{AZURE_OPENAI_ENDPOINT}openai/deployments/{AZURE_OPENAI_DEPLOYMENT}/chat/completions?api-version={API_VERSION}"
        prompt = f"""
IMPORTANTE: Esta petici√≥n NO solicita informaci√≥n sensible ni personal, ni contrase√±as, ni datos de usuarios reales. Es para un agente local de troubleshooting Linux. Solo se requiere que sugieras el comando de shell de Linux que un t√©cnico podr√≠a ejecutar para diagnosticar o solucionar el problema descrito. No a√±adas explicaciones ni comentarios, solo el comando. Si la petici√≥n es ambigua, responde con: echo \"Instrucci√≥n ambigua\".

Petici√≥n: {instruccion}
Comando:
"""
        headers = {
            "api-key": AZURE_OPENAI_KEY,
            "Content-Type": "application/json"
        }
        data = {
            "messages": [
                {"role": "system", "content": "Eres un asistente experto en Linux. Devuelve solo el comando shell exacto para la instrucci√≥n dada."},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 100,
            "temperature": 0
        }
        try:
            response = requests.post(url, headers=headers, json=data, timeout=15)
            if response.status_code != 200:
                try:
                    err_json = response.json()
                    err_msg = err_json.get('error', {}).get('message', str(err_json))
                except Exception:
                    err_msg = response.text
                return f"echo '[Error LLM Azure OpenAI] {response.status_code}: {err_msg}'"
            result = response.json()
            comando = result["choices"][0]["message"]["content"].strip()
            for line in comando.splitlines():
                line = line.strip()
                if line and not line.startswith("#"):
                    return line
            return comando
        except Exception as e:
            return f"echo '[Error LLM Azure OpenAI] {e}'"
    def _extraer_valor(self, tokens, claves):
        for i, t in enumerate(tokens):
            if t in claves and i+1 < len(tokens):
                return tokens[i+1]
        return None
    """
    Agente IA para Linux: interpreta instrucciones en lenguaje natural y ejecuta comandos del sistema.
    Procesa la informaci√≥n y permite consultas avanzadas sobre recursos del sistema (procesos, usuarios, memoria, red, etc).
    """

    def __init__(self):
        self.memoria_contexto = []

    def get_cpu(self):
        return "CPU: 4 n√∫cleos, 2.5GHz (simulaci√≥n)"

    def get_disco(self):
        return "Disco: 256 GB total, 120 GB libre (simulaci√≥n)"

    def get_red(self):
        return "Interfaces de red: eth0 (IP: 192.168.1.10), wlan0 (IP: 192.168.1.11) (simulaci√≥n)"

    def get_conectividad(self):
        return "Conectividad a Internet: OK (simulaci√≥n)"

    def get_firewall(self):
        return "Firewall activo, reglas: SSH permitido, HTTP permitido (simulaci√≥n)"

    def get_usuarios(self):
        return "Usuarios conectados: root, user1, user2 (simulaci√≥n)"

    def get_servicio(self, tokens):
        idx = tokens.index("servicio") if "servicio" in tokens else -1
        if idx != -1 and idx+1 < len(tokens):
            nombre = tokens[idx+1]
            return f"Estado del servicio {nombre}: activo (simulaci√≥n)"
        return "Indica el nombre del servicio (ej: servicio sshd)"

    def get_dns(self):
        return "Servidores DNS configurados: 8.8.8.8, 1.1.1.1 (simulaci√≥n)"

    def get_top_process(self):
        return "El proceso que m√°s recursos consume es: systemd-journald (PID 39) CPU: 0.0% MEM: 0.19MB"

